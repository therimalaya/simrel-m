<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>simrel-m: A versatile tool for simulating multi-response linear model data</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="<code>simrel-m</code>: A versatile tool for simulating multi-response linear model data">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="simrel-m: A versatile tool for simulating multi-response linear model data" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://therimalaya.github.io/simrel-m" />
  
  
  <meta name="github-repo" content="therimalaya/simrel-m" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="simrel-m: A versatile tool for simulating multi-response linear model data" />
  
  
  



<meta name="date" content="2017-03-21">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="relevant-components.html">
<link rel="next" href="references.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">Simrel-M: A versatile Simulation Tool</a></li>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="statistical-model.html"><a href="statistical-model.html"><i class="fa fa-check"></i>Statistical Model</a></li>
<li class="chapter" data-level="" data-path="relevant-components.html"><a href="relevant-components.html"><i class="fa fa-check"></i>Relevant Components</a></li>
<li class="chapter" data-level="" data-path="model-parameterization.html"><a href="model-parameterization.html"><i class="fa fa-check"></i>Model Parameterization</a><ul>
<li class="chapter" data-level="" data-path="model-parameterization.html"><a href="model-parameterization.html#position-of-relevant-components"><i class="fa fa-check"></i>Position of relevant components</a></li>
<li class="chapter" data-level="" data-path="model-parameterization.html"><a href="model-parameterization.html#data-simulation"><i class="fa fa-check"></i>Data Simulation</a></li>
<li class="chapter" data-level="" data-path="model-parameterization.html"><a href="model-parameterization.html#rotation-predictor-space"><i class="fa fa-check"></i>Rotation of predictor space</a></li>
<li class="chapter" data-level="" data-path="model-parameterization.html"><a href="model-parameterization.html#rotation-response-space"><i class="fa fa-check"></i>Rotation of response space</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li class="toc-footer"><a href="https://bookdown.org" target="blank">Published with BookDown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><code>simrel-m</code>: A versatile tool for simulating multi-response linear model data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="model-parameterization" class="section level1">
<h1>Model Parameterization</h1>
<p>In order to construct a covariance matrix of <span class="math inline">\(\mathbf{Z}\)</span> and <span class="math inline">\(\mathbf{W}\)</span> for model in equation~<a href="statistical-model.html#eq:model3">(3)</a>, we need to identify <span class="math inline">\(1/2 (p+m)(p+m+1)\)</span> unknowns. For the purpose of this simulation, we implement some assumption to re-parameterize and simplify the model parameters. This enables us to construct diverse nature of model from few key parameters.</p>
<dl>
<dt><strong>Parameterization of <span class="math inline">\(\boldsymbol{\Sigma}_{ZZ}\)</span>:</strong></dt>
<dd>Since <span class="math inline">\(\mathbf{X}\)</span>’s are principal components of <span class="math inline">\(\mathbf{X}\)</span>, the <span class="math inline">\(\boldsymbol{\Sigma}_{ZZ}\)</span> can be a diagonal matrix with eigenvalues <span class="math inline">\(\lambda_1, \ldots, \lambda_p\)</span> of predictors <span class="math inline">\(\mathbf{X}\)</span>. Further, we adopt following approximate parametric representation of these eigenvalues, <span class="math display">\[\lambda_j = e^{-\gamma(i - 1)}, \gamma &gt;0 \text{ and } j = 1, 2, \ldots, p\]</span> Here as <span class="math inline">\(\gamma\)</span> increases, the decline of eigenvalues becomes steeper and hence a single parameter <span class="math inline">\(\gamma\)</span> can be used for <span class="math inline">\(\boldsymbol{\Sigma}_{ZZ}\)</span>.
</dd>
<dt><strong>Parameterization of <span class="math inline">\(\boldsymbol{\Sigma}_{WW}\)</span>:</strong></dt>
<dd>Here, we assume that <span class="math inline">\(\mathbf{W}\)</span>’s are independent and thus their covariance matrix is considered to be Identity <span class="math inline">\(\mathbf{I}_m\)</span>.
</dd>
<dt><strong>Parameterization of <span class="math inline">\(\boldsymbol{\Sigma}_{ZW}\)</span>:</strong></dt>
<dd>After parameterization of <span class="math inline">\(\boldsymbol{\Sigma}_{ZZ}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}_{WW}\)</span>, we are left with <span class="math inline">\(m \times p\)</span> number of unknowns corresponding to <span class="math inline">\(\boldsymbol{\Sigma}_{ZW}\)</span>. The elements in this covariance matrix depends on position of x-component that are relevant for <span class="math inline">\(\mathbf{Y}\)</span>. In order to re-parameterize this covariance matrix, it is necessary to discuss about the position of relevant components in details.
</dd>
</dl>
<div id="position-of-relevant-components" class="section level2">
<h2>Position of relevant components</h2>
<p>Let only <span class="math inline">\(k_1\)</span> components are relevant for <span class="math inline">\(\mathbf{w}_1\)</span>, <span class="math inline">\(k_2\)</span> components are relevant for <span class="math inline">\(\mathbf{w}_2\)</span> and so on. Let the position of these components are given by the set <span class="math inline">\(\mathcal{P}_1, \mathcal{P}_2, \ldots, \mathcal{P}_m\)</span> respectively. Further, the covariance between <span class="math inline">\(\mathbf{w}_j\)</span> and <span class="math inline">\(\mathbf{z}_i\)</span> is non-zero only if <span class="math inline">\(\mathbf{z}_i\)</span> is relevant for <span class="math inline">\(\mathbf{w}_j\)</span>. If <span class="math inline">\(\sigma_{ij}\)</span> be the covariance between <span class="math inline">\(\mathbf{w}_j\)</span> and <span class="math inline">\(\mathbf{z_i}\)</span> then <span class="math inline">\(\sigma_{ij} \ne 0\)</span> if <span class="math inline">\(i \in \mathcal{P}_j\)</span> where <span class="math inline">\(i = 1, \ldots, p\)</span> and <span class="math inline">\(j = 1, \ldots, m\)</span> and <span class="math inline">\(\sigma_{ij} = 0\)</span> otherwise.</p>
<p>In addition, the corresponding regression coefficient for <span class="math inline">\(\mathbf{w}_j\)</span> is,</p>
<p><span class="math display">\[
\boldsymbol{\alpha}_j = \Lambda^{-1} \sigma_{ij} = \sum_{i \in \mathcal{P}_j}\frac{\sigma_{ij}}{\lambda_i}\mathbf{t}_{ij},\qquad j = 1, 2, \ldots m
\]</span></p>
<p>where, <span class="math inline">\(\mathbf{t}_{ij}\)</span> is a matrix with column vectors of 1’s and 0’s such that <span class="math inline">\(\mathbf{t}_{ij} = 1\)</span> if the position relevant components for <span class="math inline">\(\mathbf{w}_j\)</span> in set <span class="math inline">\(\mathcal{P}_j\)</span> and 0 otherwise.</p>
<p>The position of relevant components have heavy impact on prediction. <span class="citation">Inge S Helland and Almøy (<a href="#ref-helland1994comparison">1994</a>)</span> have shown that if relevant components have large variance, prediction of <span class="math inline">\(\mathbf{Y}\)</span> from <span class="math inline">\(\mathbf{X}\)</span> is relatively easy and if the variance of relevant components is small, the prediction becomes difficult given that coefficient of determination and other model parameters held constant. For example, if first and second components of <span class="math inline">\(\mathbf{X}\)</span> are relevant for <span class="math inline">\(\mathbf{Y}_1\)</span> and fifth and sixth componets are relevant for <span class="math inline">\(\mathbf{Y}_2\)</span>, it is relatively easy to predict <span class="math inline">\(\mathbf{Y}_1\)</span> than <span class="math inline">\(\mathbf{Y}_2\)</span>. Since, the first and second principal components have larger variance than fifth and sixth components.</p>
<p>Although the covariance matrix depends only on few relevant components, we can not choose these covariances freely since we also need to satisfy following two conditions:</p>
<ul>
<li>The covariance matrix must be positive definite</li>
<li>The covariance <span class="math inline">\(\sigma_{ij}\)</span> must satisfy user defined coefficient of determination</li>
</ul>
<p>We have the relation, <span class="math display">\[\boldsymbol{\rho}_W^2 = \boldsymbol{\Sigma}_{ZW}^t\boldsymbol{\Sigma}_{ZZ}^{-1}\boldsymbol{\Sigma}_{ZW}\boldsymbol{\Sigma}_{WW}^I\]</span> Applying our assumption for simulation, <span class="math inline">\(\boldsymbol{\Sigma_{WW}} = \mathbf{I}_m\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}_{ZZ} = \Lambda\)</span>, we obtain,</p>
<p><span class="math display">\[
\begin{aligned}
\boldsymbol{\rho}_W^2 &amp;= \boldsymbol{\Sigma}_{ZW}^t \Lambda^{-1} \boldsymbol{\Sigma}_{ZW} \mathbf{I}_m \\
&amp;= \begin{bmatrix}
\sum_{i = 1}^p \sigma_{i1}^2/\lambda_i          &amp; \ldots &amp; \sum_{i = 1}^p \sigma_{i1}\sigma_{im}/\lambda_i \\
\vdots                                          &amp; \ddots &amp; \vdots \\
\sum_{i = 1}^p \sigma_{i1}\sigma_{im}/\lambda_i &amp; \ldots &amp; \sum_{i = 1}^p \sigma_{im}^2/\lambda_i
\end{bmatrix}
\end{aligned}
\]</span></p>
<p>Furthermore, we assume that there are no overlapping relevant components for any two <span class="math inline">\(\mathbf{W}\)</span>, i.e, <span class="math inline">\(n\left(\mathcal{P}_j \cap \mathcal{P}_{j*}\right) = 0\)</span> or <span class="math inline">\(\sigma_{ij}\sigma_{ij*} = 0\)</span> for <span class="math inline">\(j\ne j*\)</span>. The additional unknown parameters in diagonal should agree with user specified coefficient of determination for <span class="math inline">\(\mathbf{W}_j\)</span>. i.e, <span class="math inline">\(\rho_{wj}^2\)</span> is,</p>
<p><span class="math display">\[
\rho_{wj}^2 = \sum_{i = 1}^p\frac{\sigma_{ij}^2}{\lambda_i}
\]</span></p>
<p>Here, only the relevant components have non-zero covariances with <span class="math inline">\(\mathbf{w}_j\)</span>, so,</p>
<p><span class="math display">\[
\rho_{wj}^2 = \sum_{i \in \mathcal{P}_j}\frac{\sigma_{ij}^2}{\lambda_i}
\]</span></p>
<p>For some user defined <span class="math inline">\(\rho_{jw}^2\)</span>, <span class="math inline">\(\sigma_{ij}^2\)</span> determined as follows,</p>
<ol style="list-style-type: decimal">
<li>Sample <span class="math inline">\(k_j\)</span> values from uniform distribution <span class="math inline">\(\mathcal{U}(-1, 1)\)</span> distribution. Let them be, <span class="math inline">\(\mathcal{S}_{\mathcal{P}_1}, \ldots, \mathcal{S}_{\mathcal{P}_{k_j}}\)</span>.</li>
<li>Define, <span class="math display">\[\sigma_{ij} = \text{Sign}\left(\mathcal{S}_i\right)\sqrt{\frac{\rho_{wj}^2\left|\mathcal{S}_i\right|}{\sum_{k\in \mathcal{P}_j}\left|\mathcal{S}_k\right|} \lambda_i}\]</span> for <span class="math inline">\(i \in \mathcal{P}_j\)</span> and <span class="math inline">\(j = 1, \ldots, m\)</span></li>
</ol>
</div>
<div id="data-simulation" class="section level2">
<h2>Data Simulation</h2>
<p>After the construction of <span class="math inline">\(\boldsymbol{\Xi}_{WZ}\)</span>, <span class="math inline">\(n\)</span> samples are generated from standard normal distribution of<span class="math inline">\(\left(\mathbf{W}, \mathbf{Z} \right)\)</span> considering their mean to be zero, i.e.<span class="math inline">\(\boldsymbol{\mu}_W = 0\)</span> and<span class="math inline">\(\boldsymbol{\mu}_Z=0\)</span>. Since<span class="math inline">\(\boldsymbol{\Xi}_{WZ}\)</span> is positive definite,<span class="math inline">\(\boldsymbol{\Xi}_{WZ}^{1/2}\)</span> obtained from its Cholesky decomposition, can serve as one of its square root. The simulation process constitute of following steps,</p>
<ol style="list-style-type: decimal">
<li>A matrix <span class="math inline">\(\mathbf{U}_{n\times (p + q)}\)</span> is sampled from standard normal distribution</li>
<li>Compute <span class="math inline">\(\mathbf{G} = \boldsymbol{U\Xi}_{WZ}^{1/2}\)</span></li>
</ol>
<p>Here, first <span class="math inline">\(m\)</span> columns of <span class="math inline">\(\mathbf{G}\)</span> will serve as <span class="math inline">\(\mathbf{W}\)</span> and remaining <span class="math inline">\(p\)</span> columns will serve as <span class="math inline">\(\mathbf{Z}\)</span>. Further, each row of <span class="math inline">\(\mathbf{G}\)</span> will be a vector sampled independently from joint normal distribution of <span class="math inline">\(\left(\mathbf{W}, \mathbf{Z}\right)\)</span>. The final step to generate <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{Y}\)</span> from <span class="math inline">\(\mathbf{Z}\)</span> and <span class="math inline">\(\mathbf{W}\)</span> requires corresponding rotation matrices which is discusses on following section.</p>
</div>
<div id="rotation-predictor-space" class="section level2">
<h2>Rotation of predictor space</h2>
<p>Simulation of predictor variables from principal components requires a construction of a rotation matrix <span class="math inline">\(\mathbf{R}\)</span> that defines a new basis for the same space as is spanned by the principle components. As any rotation matrix can be considered as <span class="math inline">\(\mathbf{R}\)</span>, an eigenvalue matrix from eigenvalue decomposition of <span class="math inline">\(\boldsymbol{\Sigma}_{XX}\)</span> can be a candidate. Since simulation is a reverse engineering, the underlying covariance structure for the predictors are unknown. So, the method is free to construct a real valued orthogonal matrix that can serve for the purpose.</p>
<p>Among several methods <span class="citation">(Anderson, Olkin, and Underhill <a href="#ref-anderson1987generation">1987</a>; Heiberger <a href="#ref-heiberger1978algorithm">1978</a>)</span> to generate random orthogonal matrix the same method as is used in <span class="citation">Sæbø, Almøy, and Helland (<a href="#ref-saebo2015simrel">2015</a>)</span> is implemented here. The <span class="math inline">\(\mathcal{Q}\)</span> matrix obtained from QR-decomposition of a matrix filled with standard normal variates can serve as the rotation matrix <span class="math inline">\(\mathbf{R}\)</span>.</p>
<p>The rotation can be a) unrestricted and b) restricted. The former one rotates all <span class="math inline">\(p\)</span> predictors making them some what relevant for the all response conponents and consequently all responses. However, only <span class="math inline">\(q_i \le p\)</span> predictors are relevant for for <span class="math inline">\(i^\text{th}\)</span> response component, the resticted rotation is implemented in <code>simrel-M</code>. This also ensure that <span class="math inline">\(p-q_i\)</span> predictors does not contribute anything on response component <span class="math inline">\(i\)</span> and consequently the simulated data can also be used for testing variable selection methods.</p>
</div>
<div id="rotation-response-space" class="section level2">
<h2>Rotation of response space</h2>
<p><code>Simrel-M</code> has considered an exclusive relevant predictor space for each response components, i.e. a set of predictor variables only influence one response component. However, it allows user to simulate more response variable than response components. In this case, noise are added during the orthogonal rotation of response components. For example, if user wants to simulation 5 response variation from 3 response components. Two standard normal vectors are combined with response components and rotated simultaneously. The rotation can be both restricted and unrestricted as discussed in previous section. The restricted rotation is carried out combining response vectors along with noise vector in a block-wise manner according to the users choice. Illustration in fig-…</p>
<p>Suppose, in our previous example, if response components are combined as – <span class="math inline">\(\mathbf{W}_1, \mathbf{W}_4\)</span>, <span class="math inline">\(\mathbf{W}_2\)</span> and <span class="math inline">\(\mathbf{W}_3, \mathbf{W}_5\)</span>. Here, any predictor variable is only relevant for <span class="math inline">\(\mathbf{W}_1, \mathbf{W}_2\)</span> and <span class="math inline">\(\mathbf{W}_3\)</span> while <span class="math inline">\(\mathbf{W}_4\)</span> and <span class="math inline">\(\mathbf{W}_5\)</span> are noise. The resulting response variables are <span class="math inline">\(\mathbf{Y}_1 \ldots \mathbf{Y}_5\)</span> where, the first and fourth response variable spans the same space as by the first response components <span class="math inline">\(\mathbf{W}_1\)</span> and noise component <span class="math inline">\(\mathbf{W}_4\)</span> and so on. Thus, the predictors and predictor space relevant for response component <span class="math inline">\(\mathbf{W}_1\)</span> is also relevant for response <span class="math inline">\(\mathbf{Y}_1\)</span> and <span class="math inline">\(\mathbf{Y}_4\)</span>.</p>

<!-- # References {-} -->
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-helland1994comparison">
<p>Helland, Inge S, and Trygve Almøy. 1994. “Comparison of Prediction Methods When Only a Few Components Are Relevant.” <em>Journal of the American Statistical Association</em> 89 (426). Taylor &amp;amp; Francis Group: 583–91.</p>
</div>
<div id="ref-anderson1987generation">
<p>Anderson, Theodore W, Ingram Olkin, and Les G Underhill. 1987. “Generation of Random Orthogonal Matrices.” <em>SIAM Journal on Scientific and Statistical Computing</em> 8 (4). SIAM: 625–29.</p>
</div>
<div id="ref-heiberger1978algorithm">
<p>Heiberger, Richard M. 1978. “Algorithm as 127: Generation of Random Orthogonal Matrices.” <em>Journal of the Royal Statistical Society. Series C (Applied Statistics)</em> 27 (2). JSTOR: 199–206.</p>
</div>
<div id="ref-saebo2015simrel">
<p>Sæbø, Solve, Trygve Almøy, and Inge S Helland. 2015. “Simrel-a Versatile Tool for Linear Model Data Simulation Based on the Concept of a Relevant Subspace and Relevant Predictors.” <em>Chemometrics and Intelligent Laboratory Systems</em>. Elsevier.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="relevant-components.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": true,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/therimalaya/simrel-m/edit/master/Includes/02-StatisticalModel.Rmd",
"text": "Edit"
},
"download": ["Simrel-M.epub", "Simrel-M.mobi", "Simrel-M.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
