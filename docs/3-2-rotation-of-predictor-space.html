<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="simrel-m: A versatile tool for simulating multi-response linear model data" />
<meta property="og:type" content="book" />
<meta property="og:url" content="http://therimalaya.github.io/simrel-m" />


<meta name="github-repo" content="therimalaya/simrel-m" />


<meta name="date" content="2017-05-24" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="simrel-m: A versatile tool for simulating multi-response linear model data">

<title>simrel-m: A versatile tool for simulating multi-response linear model data</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />



<style type="text/css">
  p.abstract{
    text-align: center;
    font-weight: bold;
  }
  div.abstract{
    margin: auto;
    width: 90%;
  }
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="2-statistical-model.html#statistical-model"><span class="toc-section-number">2</span> Statistical Model</a></li>
<li class="has-sub"><a href="3-relevant-components.html#relevant-components"><span class="toc-section-number">3</span> Relevant Components</a><ul>
<li class="has-sub"><a href="3-1-model-parameterization.html#model-parameterization"><span class="toc-section-number">3.1</span> Model Parameterization</a><ul>
<li><a href="3-1-model-parameterization.html#position-of-relevant-components"><span class="toc-section-number">3.1.1</span> Position of relevant components</a></li>
<li><a href="3-1-model-parameterization.html#data-simulation"><span class="toc-section-number">3.1.2</span> Data Simulation</a></li>
</ul></li>
<li><a href="3-2-rotation-of-predictor-space.html#rotation-of-predictor-space"><span class="toc-section-number">3.2</span> Rotation of predictor space</a></li>
<li><a href="3-3-rotation-of-response-space.html#rotation-of-response-space"><span class="toc-section-number">3.3</span> Rotation of response space</a></li>
</ul></li>
<li><a href="4-implementation.html#implementation"><span class="toc-section-number">4</span> Implementation</a></li>
<li><a href="5-web-interface.html#web-interface"><span class="toc-section-number">5</span> Web Interface</a></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="rotation-of-predictor-space" class="section level2">
<h2><span class="header-section-number">3.2</span> Rotation of predictor space</h2>
<p>In order to make comments on predictor space, let us consider an example where a regression model with <span class="math inline">\(p = 10\)</span> predictors <span class="math inline">\((\mathbf{x})\)</span> and <span class="math inline">\(m = 4\)</span> responses <span class="math inline">\((\mathbf{y})\)</span>. Let’s assume that only three principal components <span class="math inline">\((w_1, w_2\)</span> and <span class="math inline">\(w_3)\)</span> are needed to describe all four response variables. Further, let the index sets <span class="math inline">\(\mathcal{P}_1 = \{1, 2\}, \mathcal{P}_2 = \{3, 4\}\)</span> and <span class="math inline">\(\mathcal{P}_3 = \{5, 6\}\)</span> define the position of the principal components of <span class="math inline">\(\mathbf{x}\)</span> that are relevant for <span class="math inline">\(w_1, w_2\)</span> and <span class="math inline">\(w_3\)</span> respectively. Let <span class="math inline">\(\mathcal{S}_1\)</span>, <span class="math inline">\(\mathcal{S}_2\)</span> and <span class="math inline">\(\mathcal{S}_3\)</span> be the orthogonal spaces spanned by each set of principal components. These spaces together span <span class="math inline">\(\mathcal{S}_k = \mathcal{S}_1 \oplus \mathcal{S}_2 \oplus \mathcal{S}_3\)</span> which is the minimum relevant space and equivalent to the x-envelope as discussed by <span class="citation">Cook, Helland, and Su (<label for="tufte-mn-19" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-19" class="margin-toggle">2013<span class="marginnote">Cook, RD, IS Helland, and Z Su. 2013. “Envelopes and Partial Least Squares Regression.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 75 (5). Wiley Online Library: 851–77.</span>)</span>.</p>
<p>Moreover, let <span class="math inline">\(q_1 = 3, q_2 = 3\)</span> and <span class="math inline">\(q_3 = 2\)</span> be the number of predictor variables we want to be relevant for <span class="math inline">\(w_1, w_2\)</span> and <span class="math inline">\(w_3\)</span> respectively. Then <span class="math inline">\(q_1 = 3\)</span> predictors may be obtained by rotating the principal components in <span class="math inline">\(\mathcal{P}_1\)</span> along with one more irrelevant principal component. Similarly, <span class="math inline">\(q_2 = 3\)</span> predictors, relevant for <span class="math inline">\(w_2\)</span>, can be obtained by rotating principal components in <span class="math inline">\(\mathcal{P}_2\)</span> along with one more irrelevant component and <span class="math inline">\(q_3 = 2\)</span> predictors, relevant for <span class="math inline">\(w_3\)</span>, can be obtained by rotating principal components in <span class="math inline">\(\mathcal{P}_3\)</span> without any additional irrelevant component. Let the space spanned by the <span class="math inline">\(q_1, q_2\)</span> and <span class="math inline">\(q_3\)</span> number of predictors be <span class="math inline">\(\mathcal{S}_{q_1}\)</span>, <span class="math inline">\(\mathcal{S}_{q_2}\)</span> and <span class="math inline">\(\mathcal{S}_{q_3}\)</span>. Together they span a space <span class="math inline">\(\mathcal{S}_q = \mathcal{S}_{q_1} \oplus \mathcal{S}_{q_2} \oplus \mathcal{S}_{q_3}\)</span>. This space is bigger than <span class="math inline">\(\mathcal{S}_k\)</span>. Here, <span class="math inline">\(\mathcal{S}_k\)</span> is orthogonal to <span class="math inline">\(\mathcal{S}_{p - k}\)</span> and <span class="math inline">\(\mathcal{S}_q\)</span> is orthogonal to <span class="math inline">\(\mathcal{S}_{p - q}\)</span>. Generally speaking, here we are splitting complete variable space <span class="math inline">\(\mathcal{S}_p\)</span> into two orthogonal space – <span class="math inline">\(\mathcal{S}_k\)</span> relevant for <span class="math inline">\(\mathbf{y}\)</span> and <span class="math inline">\(\mathcal{S}_{p - k}\)</span> irrelevant for <span class="math inline">\(\mathbf{y}\)</span>.</p>
<p>In the previous section, we discussed about constructing covariance matrix of latent structure. Figure~<a href="3-2-rotation-of-predictor-space.html#fig:cov-plot-print">3.1</a> (left) shows a similar structure resembling the example here. The three colors represents their relevance with the three latent response components <span class="math inline">\((w_1, w_2\)</span> and <span class="math inline">\(w_3)\)</span>. Here we can see that <span class="math inline">\(z_{1}\)</span> and <span class="math inline">\(z_{2}\)</span> (first and second principal components of <span class="math inline">\(\mathbf{x}\)</span>) have non-zero covariance with <span class="math inline">\(w_1\)</span> (first latent component of response <span class="math inline">\(\mathbf{y}\)</span>). In the similar manner other non-zero covariances are self-explanatory.</p>
<div class="figure"><span id="fig:cov-plot-print"></span>
<p class="caption marginnote shownote">
Figure 3.1: Simulation of predictor and response variables after orthogonal transformation of principal components by a rotation matrix
</p>
<img src="Simrel-M_files/figure-html/cov-plot-print-1.png" alt="Simulation of predictor and response variables after orthogonal transformation of principal components by a rotation matrix" width="100%"  />
</div>
<p>In order to simulate predictor variables <span class="math inline">\((\mathbf{x})\)</span>, we construct matrix <span class="math inline">\(\mathbf{R}\)</span> which then is used for orthogonal rotation of principal components <span class="math inline">\(\mathbf{z}\)</span>. This defines a new basis for the same space as is spanned by the principal components. In principal, there are many possible options for a rotation matrix. Among them, the eigenvector matrix of <span class="math inline">\(\boldsymbol{\Sigma}_{xx}\)</span> can be a candidate. However, in this reverse engineering both rotation matrices <span class="math inline">\(\mathbf{R}\)</span> and <span class="math inline">\(\mathbf{Q}\)</span> along with the covariance matrices <span class="math inline">\(\boldsymbol{\Sigma}_{xx}\)</span> are unknown. So, we are free to choose any <span class="math inline">\(\mathbf{R}\)</span> that satisfied the properties of a real valued rotation matrix, i.e <span class="math inline">\(\mathbf{R}^{-1} = \mathbf{R}^t\)</span> so that <span class="math inline">\(\mathbf{R}\)</span> is orthonormal and its determinant becomes <span class="math inline">\(\pm 1\)</span>. Here the rotation matrix <span class="math inline">\(\mathbf{R}\)</span> should be block diagonal as in figure~<a href="3-2-rotation-of-predictor-space.html#fig:cov-plot-print">3.1</a> (middle) in order to rotate spaces <span class="math inline">\(\mathcal{S}_1, \mathcal{S}_2 \ldots\)</span> separately. Figure~<a href="3-2-rotation-of-predictor-space.html#fig:simulated-data">3.2</a> (left) shows the simulated principal components <span class="math inline">\(\mathbf{z}\)</span> that we are following in our example where we can see that the principal component <span class="math inline">\(z_{1}\)</span> and <span class="math inline">\(z_{2}\)</span> relevant for <span class="math inline">\(w_1\)</span> is getting rotated together with an irrelevant component <span class="math inline">\(z_{8}\)</span>. The resultant predictors (Figure~<a href="3-2-rotation-of-predictor-space.html#fig:simulated-data">3.2</a>, right) <span class="math inline">\(x_{1}, x_{2}\)</span> and <span class="math inline">\(x_{8}\)</span> will also be relevant for <span class="math inline">\(w_1\)</span>. In the figure, we can see that principal components <span class="math inline">\(x_{7}, x_{8}, x_{9}\)</span> and <span class="math inline">\(x_{10}\)</span> are not relevant for any responses before rotation however <span class="math inline">\(x_{8}, x_{10}\)</span> predictors becomes relevant after rotation keeping <span class="math inline">\(x_{7}\)</span> and <span class="math inline">\(x_{9}\)</span> still irrelevant.</p>
<div class="figure"><span id="fig:simulated-data"></span>
<p class="caption marginnote shownote">
Figure 3.2: Simulated Data before (left) and after (right) rotation
</p>
<img src="Simrel-M_files/figure-html/simulated-data-1.png" alt="Simulated Data before (left) and after (right) rotation" width="100%"  />
</div>
<p>Among several methods <span class="citation">(Anderson, Olkin, and Underhill <label for="tufte-mn-20" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-20" class="margin-toggle">1987<span class="marginnote">Anderson, Theodore W, Ingram Olkin, and Les G Underhill. 1987. “Generation of Random Orthogonal Matrices.” <em>SIAM Journal on Scientific and Statistical Computing</em> 8 (4). SIAM: 625–29.</span>; Heiberger <label for="tufte-mn-21" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-21" class="margin-toggle">1978<span class="marginnote">Heiberger, Richard M. 1978. “Algorithm as 127: Generation of Random Orthogonal Matrices.” <em>Journal of the Royal Statistical Society. Series C (Applied Statistics)</em> 27 (2). JSTOR: 199–206.</span>)</span> for generating random orthogonal matrix, in this paper we are using orthogonal matrix <span class="math inline">\(\mathcal{Q}\)</span> obtained from QR-decomposition of a matrix filled with standard normal variates. The rotation here can be a) restricted and b) unrestricted. The latter rotates all principal components <span class="math inline">\(\mathbf{z}\)</span> together and makes all predictor variables somewhat relevant for all response variables. However, the former one performs a block-wise rotation so that it rotates certain selected principal components together. This gives control for specifying certain predictors as relevant for selected responses, which was discussed in our example above. This also allows us to simulate irrelevant predictors such as <span class="math inline">\(x_{7}\)</span> and <span class="math inline">\(x_{9}\)</span> which can be detected during variables selection procedures.</p>
</div>
<p style="text-align: center;">
<a href="3-1-model-parameterization.html"><button class="btn btn-default">Previous</button></a>
<a href="https://github.com/therimalaya/simrel-m/edit/master/Includes/02-StatisticalModel.Rmd"><button class="btn btn-default">Edit</button></a>
<a href="3-3-rotation-of-response-space.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
