<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="simrel-m: A versatile tool for simulating multi-response linear model data" />
<meta property="og:type" content="book" />
<meta property="og:url" content="http://therimalaya.github.io/simrel-m" />


<meta name="github-repo" content="therimalaya/simrel-m" />


<meta name="date" content="2017-05-24" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="simrel-m: A versatile tool for simulating multi-response linear model data">

<title>simrel-m: A versatile tool for simulating multi-response linear model data</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />



<style type="text/css">
  p.abstract{
    text-align: center;
    font-weight: bold;
  }
  div.abstract{
    margin: auto;
    width: 90%;
  }
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="2-statistical-model.html#statistical-model"><span class="toc-section-number">2</span> Statistical Model</a></li>
<li class="has-sub"><a href="3-relevant-components.html#relevant-components"><span class="toc-section-number">3</span> Relevant Components</a><ul>
<li class="has-sub"><a href="3-1-model-parameterization.html#model-parameterization"><span class="toc-section-number">3.1</span> Model Parameterization</a><ul>
<li><a href="3-1-model-parameterization.html#position-of-relevant-components"><span class="toc-section-number">3.1.1</span> Position of relevant components</a></li>
<li><a href="3-1-model-parameterization.html#data-simulation"><span class="toc-section-number">3.1.2</span> Data Simulation</a></li>
</ul></li>
<li><a href="3-2-rotation-of-predictor-space.html#rotation-of-predictor-space"><span class="toc-section-number">3.2</span> Rotation of predictor space</a></li>
<li><a href="3-3-rotation-of-response-space.html#rotation-of-response-space"><span class="toc-section-number">3.3</span> Rotation of response space</a></li>
</ul></li>
<li><a href="4-implementation.html#implementation"><span class="toc-section-number">4</span> Implementation</a></li>
<li><a href="5-web-interface.html#web-interface"><span class="toc-section-number">5</span> Web Interface</a></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="statistical-model" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Statistical Model</h1>
<p>Let us consider a model in equation~<a href="2-statistical-model.html#eq:rand-reg-model">(2.1)</a> as our point of departure.</p>
<span class="math display" id="eq:rand-reg-model">\[\begin{equation}
  \begin{bmatrix}\mathbf{y}\\ \mathbf{x}\end{bmatrix} \sim N
  \left(
    \begin{bmatrix}
      \boldsymbol{\mu}_y \\
      \boldsymbol{\mu}_x
    \end{bmatrix},
    \begin{bmatrix}
      \boldsymbol{\Sigma}_{yy} &amp; \boldsymbol{\Sigma}_{yx} \\
      \boldsymbol{\Sigma}_{xy} &amp; \boldsymbol{\Sigma}_{xx}
    \end{bmatrix}
  \right)
  \tag{2.1}
\end{equation}\]</span>
<p>where, <span class="math inline">\(\mathbf{y}\)</span> is a response vector with <span class="math inline">\(m\)</span> response variables <span class="math inline">\(y_1, y_2, \ldots y_m\)</span> with mean vector of <span class="math inline">\(\boldsymbol{\mu}_y\)</span> and <span class="math inline">\(\mathbf{x}\)</span> is vector of <span class="math inline">\(p\)</span> predictor variables with mean vector <span class="math inline">\(\boldsymbol{\mu}_x\)</span>. Further,</p>
<table>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\boldsymbol{\Sigma}_{yy}\)</span></td>
<td align="left">is variance-covariance matrix of <span class="math inline">\(\mathbf{y}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\boldsymbol{\Sigma}_{xx}\)</span></td>
<td align="left">is variance-covariance matrix of variables <span class="math inline">\(\mathbf{x}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\boldsymbol{\Sigma}_{xy}\)</span></td>
<td align="left">is matrix of covariance between <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span></td>
</tr>
</tbody>
</table>

<p>For model~<a href="2-statistical-model.html#eq:rand-reg-model">(2.1)</a>, standard theory in multivariate statistics may be used to show that <span class="math inline">\(\mathbf{y}\)</span> conditioned on <span class="math inline">\(\mathbf{x}\)</span> corresponds to the linear model,</p>
<span class="math display" id="eq:linear-model">\[\begin{equation}
\mathbf{y} = \boldsymbol{\mu}_y + \boldsymbol{\beta}^t (\mathbf{x} - \boldsymbol{\mu}_x) + \boldsymbol{\varepsilon}
  \tag{2.2}
\end{equation}\]</span>
<p>where, <span class="math inline">\(\boldsymbol{\beta}^t\)</span> is a matrix of regression coefficient and <span class="math inline">\(\boldsymbol{\varepsilon}\)</span> is error term such that <span class="math inline">\(\boldsymbol{\varepsilon} \sim N\left(0, \boldsymbol{\Sigma}_{y|x}\right)\)</span>. The properties of the linear model in equation~<a href="2-statistical-model.html#eq:linear-model">(2.2)</a> can be expressed in terms of covariance matrices from equation~<a href="2-statistical-model.html#eq:rand-reg-model">(2.1)</a>.</p>
<dl>
<dt>Regression Coefficients</dt>
<dd><span class="math display">\[ \boldsymbol{\beta} = \boldsymbol{\Sigma}_{xx}^{-1}\boldsymbol{\Sigma}_{xy}\]</span>
</dd>
<dt>Coefficient of Determination <span class="math inline">\(\boldsymbol{\rho}_y^2\)</span></dt>
<dd>The diagonal elements of coefficient of determination matrix <span class="math inline">\(\boldsymbol{\rho}_y^2\)</span> gives the amount of variation that <span class="math inline">\(\mathbf{X}\)</span> has explained about each <span class="math inline">\(\mathbf{Y}\)</span>. <span class="math display">\[\boldsymbol{\rho}_y^2 = \boldsymbol{\Sigma}_{yx}\boldsymbol{\Sigma}_{xx}^{-1}\boldsymbol{\Sigma}_{xy}\boldsymbol{\Sigma}_{yy}^{-1}\]</span>
</dd>
<dt>Conditional variance</dt>
<dd>The conditional variance of <span class="math inline">\(\mathbf{y}\)</span> given <span class="math inline">\(\mathbf{x}\)</span> is, <span class="math display">\[\boldsymbol{\Sigma}_{y|x} = \boldsymbol{\Sigma}_{yy} - \boldsymbol{\Sigma}_{yx}\boldsymbol{\Sigma}_{xx}^{-1}\boldsymbol{\Sigma}_{xy}.\]</span> The diagonal elements of this matrix equals the theoretical minimum errors of prediction for each of the response variables.
</dd>
</dl>
<p>Let us define a transformation of <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{Y}\)</span> as, <span class="math inline">\(\mathbf{z} = \mathbf{Rx}\)</span> and <span class="math inline">\(\mathbf{w} = \mathbf{Qy}\)</span>. Here, <span class="math inline">\(\mathbf{R}_{p\times p}\)</span> and <span class="math inline">\(\mathbf{Q}_{m\times m}\)</span> are rotation matrices which rotates <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> giving <span class="math inline">\(\mathbf{z}\)</span> and <span class="math inline">\(\mathbf{w}\)</span> respectively. The model in equation~<a href="2-statistical-model.html#eq:rand-reg-model">(2.1)</a> can be expressed with these transformed variables as,</p>
<span class="math display" id="eq:model3">\[\begin{align}
  \begin{bmatrix}\mathbf{w} \\ 
  \mathbf{z}\end{bmatrix}  &amp; \sim N \left(\boldsymbol{\mu}, \boldsymbol{\Sigma}\right) \\
  &amp;= N \left(
    \begin{bmatrix}
      \boldsymbol{\mu}_w \\ \boldsymbol{\mu}_z
    \end{bmatrix},
    \begin{bmatrix}
      \boldsymbol{\Sigma}_{ww} &amp; \boldsymbol{\Sigma}_{wz} \\
      \boldsymbol{\Sigma}_{zw} &amp; \boldsymbol{\Sigma}_{zz}
    \end{bmatrix} \right) \nonumber \\
  &amp;= N \left(
    \begin{bmatrix}
      \boldsymbol{Q\mu}_y \\
      \boldsymbol{R\mu}_x
    \end{bmatrix},
    \begin{bmatrix}
      \boldsymbol{Q\Sigma}_{yy}\boldsymbol{Q}^t &amp; \boldsymbol{Q\Sigma}_{yx}\mathbf{R}^t \\
      \boldsymbol{R\Sigma}_{xy}\boldsymbol{Q}^t &amp; \boldsymbol{R\Sigma}_{xx}\mathbf{R}^t
    \end{bmatrix}
  \right)
  \tag{2.3}
\end{align}\]</span>
<p>In addition, a linear model relating <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\mathbf{z}\)</span> can be written as,</p>
<span class="math display" id="eq:latent-model">\[\begin{equation}
\mathbf{w} =    \boldsymbol{\mu}_w + \boldsymbol{\alpha}^t \left(\mathbf{z} - \boldsymbol{\mu}_z\right) + \boldsymbol{\tau}
\tag{2.4}
\end{equation}\]</span>
<p>where, <span class="math inline">\(\boldsymbol{\alpha}\)</span> is regression coefficient for the transformed model and <span class="math inline">\(\boldsymbol{\tau} \sim N\left(\mathbf{0}, \boldsymbol{\Sigma}_{w|z}\right)\)</span>. Further, if both <span class="math inline">\(\mathbf{Q}\)</span> and <span class="math inline">\(\mathbf{R}\)</span> are orthonormal matrix such that <span class="math inline">\(\mathbf{Q}^t\mathbf{Q} = \mathbf{I}_q\)</span> and <span class="math inline">\(\mathbf{R}^t\mathbf{R} = \mathbf{I}_p\)</span>, the inverse transformation can be defined as,</p>
<span class="math display" id="eq:cov-yx-wz">\[\begin{equation}
  \begin{matrix}
    \boldsymbol{\Sigma}_{yy} = \mathbf{Q}^t \boldsymbol{\Sigma}_{ww} \mathbf{Q} &amp;
    \boldsymbol{\Sigma}_{yx} = \mathbf{Q}^t \boldsymbol{\Sigma}_{wz} \mathbf{R} \\
    \boldsymbol{\Sigma}_{xy} = \mathbf{R}^t \boldsymbol{\Sigma}_{zw} \mathbf{Q} &amp;
    \boldsymbol{\Sigma}_{xx} = \mathbf{R}^t \boldsymbol{\Sigma}_{zz} \mathbf{R}
  \end{matrix}
  \tag{2.5}
\end{equation}\]</span>
<p>Here, we can find a direct connection between different population properties between <a href="2-statistical-model.html#eq:linear-model">(2.2)</a> and <a href="2-statistical-model.html#eq:latent-model">(2.4)</a>.</p>
<dl>
<dt>Regression Coefficients</dt>
<dd><span class="math display">\[
  \begin{aligned}
  \boldsymbol{\alpha} &amp;= \boldsymbol{\Sigma}_{wz} \boldsymbol{\Sigma}_{zz}^{-1}
  &amp;&amp;= \boldsymbol{Q\Sigma}_{YZ}\mathbf{R}^t\left[\boldsymbol{R\Sigma}_{xx}\mathbf{R}^t\right]^{-1} \\
  &amp;= \mathbf{Q}\left[\boldsymbol{\Sigma}_{yx}\boldsymbol{\Sigma}_{xx}^{-1}\right]\mathbf{R}^t
  &amp;&amp;= \mathbf{Q}\boldsymbol{\beta}\mathbf{R}^t
  \end{aligned}
  \]</span>
</dd>
<dt>Error Variance</dt>
<dd>Further, the noise variance of transformed model~<a href="2-statistical-model.html#eq:latent-model">(2.4)</a> is, <span class="math display">\[
  \begin{aligned}
\boldsymbol{\Sigma}_{w|z}
&amp;= \boldsymbol{Q\Sigma}_{yy}\mathbf{Q}^t -
  \boldsymbol{Q \Sigma}_{yx}\mathbf{R}^t \left[\boldsymbol{R\Sigma}_{xx}\boldsymbol{R}^t\right]^{-1}
  \boldsymbol{R\Sigma}_{xy}\mathbf{Q}^t \nonumber \\
&amp;= \boldsymbol{Q\Sigma}_{yy}\mathbf{Q}^t - 
  \boldsymbol{Q \Sigma}_{yx}\boldsymbol{\Sigma}_{xx}^{-1}\boldsymbol{\Sigma}_{xy}\mathbf{Q}^t \nonumber \\
&amp;= \mathbf{Q}\left[\boldsymbol{\Sigma}_{yy} -
  \boldsymbol{\Sigma}_{yx}\boldsymbol{\Sigma}_{xx}^{-1}\boldsymbol{\Sigma}_{xy}\right]\mathbf{Q}^{t} \nonumber \\
&amp;= \mathbf{Q} \boldsymbol{\Sigma}_{y|x}\mathbf{Q}^t
  \end{aligned}
  \]</span>
</dd>
<dt>Coefficient of Determination</dt>
<dd>The coefficient of determination for model~<a href="2-statistical-model.html#eq:latent-model">(2.4)</a> is, <span class="math display">\[
  \begin{aligned}
\boldsymbol{\rho}^2_w &amp;= \boldsymbol{\Sigma}_{wz} 
\boldsymbol{\Sigma}_{zz}^{-1} \boldsymbol{\Sigma}_{zw} 
\boldsymbol{\Sigma}_{ww}^{-1} \\
  &amp;=\mathbf{Q}^t
  \boldsymbol{\Sigma}_{yx}\mathbf{R}^t \left(\mathbf{R}\boldsymbol{\Sigma}_{xx}\mathbf{R}^t\right)^{-1}
  \mathbf{R}\boldsymbol{\Sigma}_{xy}\mathbf{Q}^t \left(\mathbf{Q} \boldsymbol{\Sigma}_{yy}^{-1} \mathbf{Q}^t\right) \nonumber \\
  &amp;=\mathbf{Q}^t\left[\boldsymbol{\Sigma}_{yx}\boldsymbol{\Sigma}_{xx}\boldsymbol{\Sigma}_{xy}\boldsymbol{\Sigma}_{yy}^{-1}\right]\mathbf{Q} \\
  &amp;= \mathbf{Q}\boldsymbol{\rho}_{Y}^2 \mathbf{Q}^t
  \end{aligned}
  \]</span>
</dd>
</dl>
<p>From eigenvalue decomposition principal, if <span class="math inline">\(\boldsymbol{\Sigma}_{xx} = \mathbf{R}\boldsymbol{\Lambda}\mathbf{R}^t\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}_{yy} = \mathbf{Q}\boldsymbol{\Omega}\mathbf{Q}^t\)</span> then <span class="math inline">\(\mathbf{z}\)</span> and <span class="math inline">\(\mathbf{w}\)</span> can be interpreted as principal components of <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> respectively. In this paper, these principal components will be termed as <em>predictor components</em> and <em>response components</em> respectively. Here, <span class="math inline">\(\boldsymbol{\Sigma}\)</span> and <span class="math inline">\(\boldsymbol{\Omega}\)</span> are diagonal matrices of eigenvalues of <span class="math inline">\(\boldsymbol{\Sigma}_{xx}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}_{yy}\)</span> respectively.</p>
</div>
<p style="text-align: center;">
<a href="index.html"><button class="btn btn-default">Previous</button></a>
<a href="https://github.com/therimalaya/simrel-m/edit/master/Includes/02-StatisticalModel.Rmd"><button class="btn btn-default">Edit</button></a>
<a href="3-relevant-components.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
