<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="simrel-m: A versatile tool for simulating multi-response linear model data" />
<meta property="og:type" content="book" />
<meta property="og:url" content="http://therimalaya.github.io/simrel-m" />


<meta name="github-repo" content="therimalaya/simrel-m" />


<meta name="date" content="2017-05-24" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="simrel-m: A versatile tool for simulating multi-response linear model data">

<title>simrel-m: A versatile tool for simulating multi-response linear model data</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />



<style type="text/css">
  p.abstract{
    text-align: center;
    font-weight: bold;
  }
  div.abstract{
    margin: auto;
    width: 90%;
  }
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="2-statistical-model.html#statistical-model"><span class="toc-section-number">2</span> Statistical Model</a></li>
<li class="has-sub"><a href="3-relevant-components.html#relevant-components"><span class="toc-section-number">3</span> Relevant Components</a><ul>
<li class="has-sub"><a href="3-1-model-parameterization.html#model-parameterization"><span class="toc-section-number">3.1</span> Model Parameterization</a><ul>
<li><a href="3-1-model-parameterization.html#position-of-relevant-components"><span class="toc-section-number">3.1.1</span> Position of relevant components</a></li>
<li><a href="3-1-model-parameterization.html#data-simulation"><span class="toc-section-number">3.1.2</span> Data Simulation</a></li>
</ul></li>
<li><a href="3-2-rotation-of-predictor-space.html#rotation-of-predictor-space"><span class="toc-section-number">3.2</span> Rotation of predictor space</a></li>
<li><a href="3-3-rotation-of-response-space.html#rotation-of-response-space"><span class="toc-section-number">3.3</span> Rotation of response space</a></li>
</ul></li>
<li><a href="4-implementation.html#implementation"><span class="toc-section-number">4</span> Implementation</a></li>
<li><a href="5-web-interface.html#web-interface"><span class="toc-section-number">5</span> Web Interface</a></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="model-parameterization" class="section level2">
<h2><span class="header-section-number">3.1</span> Model Parameterization</h2>
<p>In order to construct a fully specified covariance matrix of <span class="math inline">\(\mathbf{z}\)</span> and <span class="math inline">\(\mathbf{w}\)</span> for model in equation~<a href="2-statistical-model.html#eq:model3">(2.3)</a>, we need to identify <span class="math inline">\(1/2 (p+m)(p+m+1)\)</span> unknown parameters<span style="color:red;">Some Motivation for simplification of parameters</span>(<span style="color:green;">See comment from Solve</span>). For the purpose of this simulation, we implement some assumption to re-parameterize and simplify the model parameters. This enables us to construct a wide range of model properties from few key parameters.</p>
<dl>
<dt><strong>Parameterization of <span class="math inline">\(\boldsymbol{\Sigma}_{zz}\)</span></strong></dt>
<dd>If we consider the rotation matrix <span class="math inline">\(\mathbf{R}\)</span> corresponds to the eigenvectors of <span class="math inline">\(\boldsymbol{\Sigma}_{xx}\)</span>, then <span class="math inline">\(\mathbf{z}\)</span> becomes the set of principal components of <span class="math inline">\(\mathbf{x}\)</span>. In that case <span class="math inline">\(\boldsymbol{\Sigma}_{zz}\)</span> is a diagonal matrix with eigenvalues <span class="math inline">\(\lambda_1, \ldots, \lambda_p\)</span>. Further, we adopt the following parametric representation of these eigenvalues, <span class="math display">\[\lambda_j = e^{-\gamma(j - 1)}, \gamma &gt;0 \text{ and } j = 1, 2, \ldots, p\]</span> Here as <span class="math inline">\(\gamma\)</span> increases, the decline of eigenvalues becomes steeper, hence the parameter <span class="math inline">\(\gamma\)</span> controls the level of multicollinearity in <span class="math inline">\(\mathbf{x}\)</span>.
</dd>
<dt><strong>Parameterization of <span class="math inline">\(\boldsymbol{\Sigma}_{ww}\)</span></strong></dt>
<dd>Here, we assume that <span class="math inline">\(\mathbf{w}\)</span>’s are independent unconditionally equally mutinormal distributed with variance 1, hence <span class="math inline">\(\boldsymbol{\Sigma}_{ww} = \mathbf{I}_m\)</span>.
</dd>
<dt><strong>Parameterization of <span class="math inline">\(\boldsymbol{\Sigma}_{zw}\)</span></strong></dt>
<dd>After parameterization of <span class="math inline">\(\boldsymbol{\Sigma}_{zz}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}_{ww}\)</span>, we are left with <span class="math inline">\(m \times p\)</span> number of unknowns corresponding to <span class="math inline">\(\boldsymbol{\Sigma}_{zw}\)</span>. Some of the elements of <span class="math inline">\(\boldsymbol{\Sigma}_{zw}\)</span> may be equal to zero, which implies that the given <span class="math inline">\(\mathbf{z}\)</span> is irrelevant for the given variable <span class="math inline">\(\mathbf{w}\)</span>. The non-zero elements define which of the <span class="math inline">\(\mathbf{z}\)</span> are relevant for the <span class="math inline">\(\mathbf{w}\)</span>. We typically refer to the indices of these <span class="math inline">\(\mathbf{z}\)</span> variables as the position of relevant components. In order to re-parameterize this covariance matrix, it is necessary to discuss the position of relevant components in details.
</dd>
</dl>
<div id="position-of-relevant-components" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Position of relevant components</h3>
<p>Let <span class="math inline">\(k_1\)</span> components be relevant for <span class="math inline">\(\mathbf{w}_1\)</span>, <span class="math inline">\(k_2\)</span> components be relevant for <span class="math inline">\(\mathbf{w}_2\)</span> and so on. Let the positions of these components be given by the index sets <span class="math inline">\(\mathcal{P}_1, \mathcal{P}_2, \ldots, \mathcal{P}_m\)</span> respectively. Further, the covariance between <span class="math inline">\(\mathbf{w}_j\)</span> and <span class="math inline">\(\mathbf{z}_i\)</span> is non-zero only if <span class="math inline">\(\mathbf{z}_i\)</span> is relevant for <span class="math inline">\(\mathbf{w}_j\)</span>. If <span class="math inline">\(\sigma_{ij}\)</span> is the covariance between <span class="math inline">\(\mathbf{w}_j\)</span> and <span class="math inline">\(\mathbf{z_i}\)</span> then <span class="math inline">\(\sigma_{ij} \ne 0\)</span> if <span class="math inline">\(i \in \mathcal{P}_j\)</span> where <span class="math inline">\(i = 1, \ldots, p\)</span> and <span class="math inline">\(j = 1, \ldots, m\)</span> and <span class="math inline">\(\sigma_{ij} = 0\)</span> otherwise.</p>
<p>In addition, the true regression coefficients for <span class="math inline">\(w_j\)</span> (equation~<a href="2-statistical-model.html#eq:latent-model">(2.4)</a>) is given by:</p>
<p><span class="math display">\[
\boldsymbol{\alpha}_j = \Lambda^{-1} \sigma_{ij} = \sum_{i \in \mathcal{P}_j}\frac{\sigma_{ij}}{\lambda_i},\qquad j = 1, 2, \ldots m
\]</span></p>
<p>The position of relevant components have heavy impact on prediction. <span class="citation">Helland and Almøy (<label for="tufte-mn-18" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-18" class="margin-toggle">1994<span class="marginnote">Helland, Inge S, and Trygve Almøy. 1994. “Comparison of Prediction Methods When Only a Few Components Are Relevant.” <em>Journal of the American Statistical Association</em> 89 (426). Taylor &amp;amp; Francis Group: 583–91.</span>)</span> have shown that if relevant components have large eigenvalues (variances), which here implies small index values in <span class="math inline">\(\mathcal{P}_j\)</span>, prediction of <span class="math inline">\(\mathbf{y}\)</span> from <span class="math inline">\(\mathbf{x}\)</span> is relatively easy and if the eigenvalues (variances) of relevant components are small, the prediction becomes difficult given that the coefficient of determination and other model parameters are held constant. For example, if the first and second components, <span class="math inline">\(\mathbf{z}_1\)</span> and <span class="math inline">\(\mathbf{z}_2\)</span>, are relevant for <span class="math inline">\(\mathbf{w}_1\)</span> and fifth and sixth components, <span class="math inline">\(\mathbf{z}_5\)</span> and <span class="math inline">\(\mathbf{z}_6\)</span>, are relevant for <span class="math inline">\(\mathbf{w}_2\)</span>, it is relatively easier to predict <span class="math inline">\(\mathbf{w}_1\)</span> than <span class="math inline">\(\mathbf{w}_2\)</span>, other properties being similar. This is so, because the first and second principal components have larger variances than the fifth and sixth components.</p>
<p>Although the covariance matrix may depends on few relevant components, we can not choose these covariances freely since we also need to satisfy following two conditions:</p>
<ul>
<li>The covariance matrices <span class="math inline">\(\Sigma_{zz}\)</span>, <span class="math inline">\(\Sigma_{ww}\)</span> and <span class="math inline">\(\Sigma\)</span> must be positive definite</li>
<li>The covariance <span class="math inline">\(\sigma_{ij}\)</span> must satisfy user defined coefficient of determination</li>
</ul>
<p>We have the relation, <span class="math display">\[\boldsymbol{\rho}_w^2 = \boldsymbol{\Sigma}_{zw}^t\boldsymbol{\Sigma}_{zz}^{-1}\boldsymbol{\Sigma}_{zw}\boldsymbol{\Sigma}_{ww}^{-1}\]</span> Applying our above given assumptions that, <span class="math inline">\(\boldsymbol{\Sigma_{ww}} = \mathbf{I}_m\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}_{zz} = \Lambda\)</span>, we obtain,</p>
<p><span class="math display">\[
\begin{aligned}
\boldsymbol{\rho}_w^2 &amp;= \boldsymbol{\Sigma}_{zw}^t \Lambda^{-1} \boldsymbol{\Sigma}_{zw} \mathbf{I}_m \\
&amp;= \begin{bmatrix}
\sum_{i = 1}^p \sigma_{i1}^2/\lambda_i          &amp; \ldots &amp; \sum_{i = 1}^p \sigma_{i1}\sigma_{im}/\lambda_i \\
\vdots                                          &amp; \ddots &amp; \vdots \\
\sum_{i = 1}^p \sigma_{i1}\sigma_{im}/\lambda_i &amp; \ldots &amp; \sum_{i = 1}^p \sigma_{im}^2/\lambda_i
\end{bmatrix}
\end{aligned}
\]</span></p>
<p>Furthermore, we assume that there are no overlapping relevant components for any two <span class="math inline">\(\mathbf{w}\)</span>, i.e, <span class="math inline">\(n\left(\mathcal{P}_j \cap \mathcal{P}_{j*}\right) = 0\)</span> or <span class="math inline">\(\sigma_{ij}\sigma_{ij*} = 0\)</span> for <span class="math inline">\(j\ne j*\)</span>. The additional unknown parameters in diagonal of <span class="math inline">\(\boldsymbol{\rho}_w^2\)</span> should agree with user specified coefficient of determination for <span class="math inline">\(\mathbf{w}_j\)</span>. i.e, <span class="math inline">\(\rho_{wj}^2\)</span> is,</p>
<p><span class="math display">\[
\rho_{wj}^2 = \sum_{i = 1}^p\frac{\sigma_{ij}^2}{\lambda_i}
\]</span></p>
<p>Here, only the relevant components have non-zero covariances with <span class="math inline">\(\mathbf{w}_j\)</span>, so,</p>
<p><span class="math display">\[
\rho_{wj}^2 = \sum_{i \in \mathcal{P}_j}\frac{\sigma_{ij}^2}{\lambda_i}
\]</span></p>
<p>For some user defined <span class="math inline">\(\rho_{jw}^2\)</span>, <span class="math inline">\(\sigma_{ij}^2\)</span> is determined as follows,</p>
<ol style="list-style-type: decimal">
<li>Sample <span class="math inline">\(k_j\)</span> values from a uniform distribution <span class="math inline">\(\mathcal{U}(-1, 1)\)</span> distribution. Let them be, <span class="math inline">\(\mathcal{S}_{\mathcal{P}_1}, \ldots, \mathcal{S}_{\mathcal{P}_{k_j}}\)</span>.</li>
<li>Define, <span class="math display">\[\sigma_{ij} = \text{Sign}\left(\mathcal{S}_i\right)\sqrt{\frac{\rho_{wj}^2\left|\mathcal{S}_i\right|}{\sum_{k\in \mathcal{P}_j}\left|\mathcal{S}_k\right|} \lambda_i}\]</span> for <span class="math inline">\(i \in \mathcal{P}_j\)</span> and <span class="math inline">\(j = 1, \ldots, m\)</span></li>
</ol>
</div>
<div id="data-simulation" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Data Simulation</h3>
<p>From the above given parameterizations and the user defined choices of model parameters, a fully defined and known covariance matrix <span class="math inline">\(\boldsymbol{\Sigma}\)</span> of <span class="math inline">\((\mathbf{w, z})\)</span> is given. For the simulation of a single observation of <span class="math inline">\((\mathbf{w, z})\)</span> let us define <span class="math inline">\(\mathbf{g} = \boldsymbol{\Sigma}^{-1/2}\mathbf{u}\)</span> such that <span class="math inline">\(\text{cov}(\mathbf{g}) = \boldsymbol{\Sigma}\)</span>. Here <span class="math inline">\(\boldsymbol{\Sigma}^{-1/2}\)</span> is obtained from Choleskey decomposition and serves as one of the square root of positive definite matrix <span class="math inline">\(\boldsymbol{\Sigma}\)</span> and <span class="math inline">\(\mathbf{u}\)</span> is simulated from standard normal distribution and has covariance <span class="math inline">\(\text{cov}(u) = \mathbf{I}\)</span>.</p>
<p>Similarly, in order to simulate <span class="math inline">\(n\)</span> observations, we define <span class="math inline">\(\underset{n \times (m + p)}{\mathbf{G}} = \mathbf{U}\boldsymbol{\Sigma}^{-1/2}\)</span> such that <span class="math inline">\(\text{cov}(\mathbf{G}) = \boldsymbol{\Sigma}\)</span>. Here the first <span class="math inline">\(m\)</span> columns of <span class="math inline">\(\mathbf{G}\)</span> will serve as <span class="math inline">\(\mathbf{W}\)</span> and remaining <span class="math inline">\(p\)</span> columns will serve as <span class="math inline">\(\mathbf{Z}\)</span>. Further, each row of <span class="math inline">\(\mathbf{G}\)</span> will be a vector sampled independently from joint normal distribution of <span class="math inline">\(\left(\mathbf{w}, \mathbf{z}\right)\)</span>. Finally, these simulated matrices <span class="math inline">\(\mathbf{W}\)</span> and <span class="math inline">\(\mathbf{Z}\)</span> are orthogonally rotated in order to obtain <span class="math inline">\(\mathbf{Y}\)</span> and <span class="math inline">\(\mathbf{X}\)</span> respectively. Following section discuss about these rotation matrices in details.</p>
</div>
</div>
<p style="text-align: center;">
<a href="3-relevant-components.html"><button class="btn btn-default">Previous</button></a>
<a href="https://github.com/therimalaya/simrel-m/edit/master/Includes/02-StatisticalModel.Rmd"><button class="btn btn-default">Edit</button></a>
<a href="3-2-rotation-of-predictor-space.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
