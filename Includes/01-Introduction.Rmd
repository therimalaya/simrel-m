# Introduction

_General aspects_

Technological advancement has opened a door for complex and sophisticated scientific experiments that was not possible before. Due to this change, enormous amounts of raw data are generated which contains massive information but difficult to excavate. Finding information and performing scientific research on these raw data is now becoming another problem. In order to tackle this situation new methods are being developed. However, before implementing any methods, it is essential to test its performance. Often, researchers use simulated data for the purpose which itself is a time-consuming process. The main focus of this paper is to present a simulation method, along with an r-package called `simrel-m`, that is versatile in nature and yet simple to use. 

The method is based on principal of relevant space for prediction which assumes that there exists a subspace in the complete space of responses that is spanned by a subset of eigenvectors of predictor variables. The method and the r-package based on this principle not only has ability to simulate wide range of multi-response linear model data but also let researcher to specify which components of predictors $(\mathbf{X})$ are relevant for a component of responses $\mathbf{Y}$. This enables the possibility to construct data for evaluating methods developed for variable selection. 

A vast literature on simulation is present but most of them are developed to address the specific problems their study was dealing with. @saebo2015simrel has presented a generic tool that is capable of simulating linear model data as an r-package `simrel`. This paper extends the methods to simulate multivariate response.

_Application of `simrel-m`_

The simple interface of `simrel-m` for sophisticated simulation opens for numerous applications in various disciplines among which some of them are discussed below.

_Educational Purpose:_
  : Explaining multivariate statistics and edify people is a difficult and strategic task. Instructors spend lots of time just to find suitable datasets for explaining some issue. For instance --  
  

_Model and methods testing:_
  : Imagine a situation where a researcher is collecting enormous amount of data which takes both time and money. Before going into extensive sampling, a pilot project is started and samples were collected using various techniques. Each of them are modelled with different estimation methods. The researcher would like to compare the sampling methods or estimation procedures that will the suitable for the final project. A simulated dataset based on the pilot project may help to identify the most appropriate sampling methods or estimation procedures.
  
  
_Understanding and developing multivariate statistics:_
  : New estimation methods are being developed to address mordern and complicated situations. A new method or technique could be difficult to understand. For example, the envelope model @cook2015foundations, a recent estimation technique based on maximum likelihood, attempts to find a response envelope (relevant subspace) that contains all the information that the corresponding predictors can explain. Here, one can make use of `simrel-m` to simulate data with underlying informative response space. In addition, new methods such as CPLS based on PLS are steadily being developed. Understanding population latent structure enables assessment of such models.
  
## Model Specification

A multi-response multivariate general linear model in equation-\@ref(eq:model1) is conidered as a simulation model.

Being an extension of `simrel` package, a quick summary of the procedure used in that package  helps to underestand the literature in this paper.

### An overview of `simrel`

`Simrel` is based on uni-response linear model as in equation~\@ref(eq:simrel-model).

\begin{equation}
(\#eq:simrel-model)
  \begin{bmatrix}
    y \\ \mathbf{X}
  \end{bmatrix} \sim
  \mathcal{N}\left(
    \begin{bmatrix}
      \mu_y \\ \boldsymbol{\mu_X}
    \end{bmatrix},
    \begin{bmatrix}
      \sigma_y^2               & \boldsymbol{\sigma_{Xy}}^t \\
      \boldsymbol{\sigma_{Xy}} & \boldsymbol{\Sigma_{XX}}
    \end{bmatrix}
  \right)
\end{equation}

\begin{equation}
  \mathbf{Y} = \boldsymbol{\mu}_Y + \boldsymbol{B}^t (\mathbf{X} - \boldsymbol{\mu}_X) + \boldsymbol{\epsilon}
  (\#eq:model1)
\end{equation}

where $\mathbf{Y}$ is a response matrix with $m$ response vector $y_1, y_2, \ldots y_m$, $\mathbf{X}$ is multivariate predictor matrix with $p$ predictor variables and the random error term $\boldsymbol{\epsilon}$ is assumed to follow $N(\boldsymbol{0},\; \boldsymbol{\Sigma}_{Y|X})$. Equivalently,

\begin{equation}
  \begin{bmatrix}\mathbf{Y}\\ \mathbf{X}\end{bmatrix} \sim N(\boldsymbol{\mu}, \boldsymbol{\Sigma})
  = N \left(
    \begin{bmatrix}
      \boldsymbol{\mu}_Y \\
      \boldsymbol{\mu}_X
    \end{bmatrix},
    \begin{bmatrix}
      \boldsymbol{\Sigma}_{YY} & \boldsymbol{\Sigma}_{XY}^t \\
      \boldsymbol{\Sigma}_{XY} & \boldsymbol{\Sigma}_{XX}
    \end{bmatrix}
  \right)
  (\#eq:model2)
\end{equation}

Here,

$\boldsymbol{\Sigma}_{YY}$ :                    Covariance Matrix of response $\mathbf{Y}$ without given $\mathbf{X}$            
$\boldsymbol{\Sigma}_{XY}$ :                    Covariance Matrix between $\mathbf{X}$ and $\mathbf{Y}$                      
$\boldsymbol{\Sigma}_{XX}$ :                    Covariance matrix of predictor variables $\mathbf{X}$                            
$\boldsymbol{\mu}_X$ and $\boldsymbol{\mu}_Y$ : Mean vectors of response $\mathbf{Y}$ and predictor $\mathbf{X}$ respective 
                                                                                                                                     
According to the theory of Multivariate Normal Distribution, we can express different parameters interms of $\mathbf{X}$, $\mathbf{Y}$ and the covariance structure.

### Model Parameterization

`Simrel-m` uses model parameterization which is based on the concept of relevant components @helland1994comparison where it is assumed that a subspace of response $\mathbf{Y}$ is spanned by a subset of eigenvectors corresponding to predictor space. A response space can be thought to have two mutually orthogonal space -- relevant and irrelevant. Here the relevant space of response matrix is termed as response components, and we assume that each response component is spanned by an exclusive subset of predictor variables. In this way we can construct a set of predictor variables which has non-zero regression coefficients. This also enables user to have uninformative predictors which can be detected during variable selection procedure. In addition, user can control signal-to-noise ratio for each response components with a vector of population coefficient of determination $\rho_1, \ldots, \rho_q$. Further, the collinearity between predictor variables can also be controlled by a factor $\gamma$ which guides the decay pattern of eigenvalue of $\mathbf{X}$ matrix. @helland1994comparison showed that if the direction of large variablity (i.e., component corresponding to large eigenvalues) are also relevant relevant predictor space, prediction is relatively easy. In contrast, if the relevant predictors are on the direction of low varibility, prediction becomes difficult.

_Parameter Definition:_

Before continuing any further, it is necessary to define the parameters used here,

Table: (#tab:parameters) Parameters for simulation used in this study

| Parameters      | Description                                                                                        |
|:---------------:|----------------------------------------------------------------------------------------------------|
| $n$             | number of observations                                                                             |
| $p$             | number of predictors                                                                               |
| $q$             | numbers of relevant predictors for each response components                                        |
| $l$             | number of response components                                                                      |
| $m$             | number of response                                                                                 |
| $\mathcal{P}$   | set of position index of relevant components for each response components                          |
| $\gamma$        | degree of collinearity, factor that control the decrease of eigenvalue of $\mathbf{X}$             |
| $\mathcal{S}$   | set of index of response components for simulation orthogonal rotation to simulation $m$ responses |
| $\mathcal{R}^2$ | population coefficient determination for each response components                                  |

In the following section, some of these parameters are discussed in detail. The discussion has considered random $\mathbf{X}$ regression model with $m$ response as given in equation~\@ref(eq:model1).

_Parameters Explanation and Notation Used:_

Let $m$ responses are spanned completely by $l$ response components. These $l$ response components are combined with $m-l$ standard normal vectors by user defined criteria to get $m$ responses after successive orthogonal transformation. Out of $q$, let $q_j,\; j = 1, \ldots l$ be the number of predictors that is relevant for response $j$. Let $c_j$ be the number of eigenvectors/ components that completely span $j^\text{th}$ predictor space containing $q_j$ number of predictors. Further, the position of these components for $j^\text{th}$ response be in index set $\mathcal{P}_j$. Here it is also assumed that the eigenvalues corresponding to $\mathbf{X}$ declines successively such that $\lambda_i, i = 1, \ldots, p$ such that $\lambda_i \ge \lambda_k, i > k$ are the eigen values of $\mathbf{X}$. The position index of eigenvalues corresponding to response $j$ is in the set $\mathcal{P}_j$. We assume that the index are ordered within each sets so that, $j^\text{th}$ index set contains $c_j$ number of components. The eigenvalues corresponding to these components in $\mathcal{P}_j$ set is $\lambda_{\mathcal{P}_{jk}}, k = 1, \ldots c_j$ such that $\lambda_{\mathcal{P}_{jk}} > \lambda_{\mathcal{P}_{jk'}}$ for $k > k'$. In `Simrel-M` package, we refer this position by `relpos` argument. In addition, we suppose that the relevant components are exclusive for each response.

_An Example:_

Suppose we have a situation like,

-------------------------------------------------------------- ------------------- --- ---------------------------
                                            Number of response $(m)$                =   5                         
                                 Number of response components $(l)$                =   3                         
                 Position of relevant component for response 1 $(\mathcal{P}_1)$    =   $\left\{ 1, 3 \right\}$   
                 Position of relevant component for response 2 $(\mathcal{P}_2)$    =   $\left\{ 2, 4, 5 \right\}$
                 Position of relevant component for response 3 $(\mathcal{P}_3)$    =   $\left\{ 6 \right\}$      
-------------------------------------------------------------- ------------------- --- ---------------------------

such that, $\lambda_1 > \lambda_3$ in $\mathcal{P}_1$ and $\lambda_2 > \lambda_4 > \lambda_5$ in set $\mathcal{P}_2$. Here, the component (eigenvector) 1 and 3 are relevant for response component 1, component 2, 4 and 5 are relevant for response component 2 and component 6 is relevant for response component 3.

In `Simrel-M`, we have assumed that the eigenvalues are decreasing exponentially by factor $\gamma$ and the largest eigenvalue is 1, i.e. for $\gamma > 0$, $\lambda_i = \text{e}^{-\gamma(i-1)}$ for $i = 1, 2, \ldots p$.